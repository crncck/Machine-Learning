{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf8be82",
   "metadata": {},
   "source": [
    "# Data Preprocessing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a96cde",
   "metadata": {},
   "source": [
    "**Data preprocessing** is a step in the data mining and data analysis process that takes raw data and transforms it into a format that can be understood and analyzed by computers and machine learning.\n",
    "\n",
    "Data preprocessing is important to improve the overall data quality.\n",
    "\n",
    "Why is data preprocessing important?\n",
    "\n",
    "- Duplicate or missing values may give an incorrect view of the overall statistics of data.\n",
    "- Outliers and inconsistent data points often tend to disturb the model’s overall learning, leading to false predictions.\n",
    "Data preprocessing handles them.\n",
    "\n",
    "There are four main steps of data preprocessing. Which are:\n",
    "- Data Cleaning\n",
    "- Data Intergration\n",
    "- Data Transformation\n",
    "- Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbdbed",
   "metadata": {},
   "source": [
    "**1. Data Cleaning:**\n",
    "\n",
    "It is the process of adding missing data and correcting, repairing, or removing incorrect or irrelevant data from a dataset.\n",
    "\n",
    "\n",
    "- **Missing data:** Some data is missing in the dataset. It can be handled in various ways:\n",
    "\n",
    "    - Ignore the tuples: when dataset is huge and multiple values are missing within a tuple.\n",
    "\n",
    "    - Fill the missing values: fill the missing values manually, by attribute mean or the most probable value.\n",
    "    \n",
    "\n",
    "- **Noisy data:** It is a meaningless data. It can be generated due to faulty data collection, data entry errors. It can be handled in following ways :\n",
    "\n",
    "    - Binning: It works on sorted data values. The data is divided into equal-sized bins, and each bin/bucket is dealt with independently. \n",
    "\n",
    "    - Regression: It helps to smoothen noise by fitting all the data points in a regression function. The regression used may be linear (having one independent variable) or multiple (having multiple independent variables).\n",
    "   \n",
    "    - Clustering: Creation of groups/clusters from data having similar values. The values that don't lie in the cluster can be treated as noisy data and can be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5e4fd",
   "metadata": {},
   "source": [
    "**2. Data Integration:**\n",
    "\n",
    "It is one of the data preprocessing steps that are used to merge the data present in multiple sources into a single larger data store like a data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112afec",
   "metadata": {},
   "source": [
    "**3. Data Transformation:**\n",
    "\n",
    "It is taken in order to transform the data in appropriate forms suitable for mining process. This involves following ways:\n",
    "\n",
    "- **Aggregation:** Data aggregation combines all of your data together in a uniform format.\n",
    "\n",
    "\n",
    "- **Normalization:** It is done in order to scale the data values in a specified range (-1.0 to 1.0 or 0.0 to 1.0).\n",
    "\n",
    "    - Min-max normalization\n",
    "    - Z-Score normalization\n",
    "    - Decimal scaling normalization\n",
    "    \n",
    "    \n",
    "- **Feature selection:** Feature selection is the process of deciding which variables are most important to your analysis. New properties of data are created from existing attributes to help in the data mining process.\n",
    "\n",
    "\n",
    "- **Discreditization:** This is done to replace the raw values of numeric attribute by interval levels or conceptual levels.\n",
    "\n",
    "\n",
    "- **Concept hierarchy generation:** Concept hierarchy generation can add a hierarchy within and between your features that wasn’t present in the original data. If your analysis contains wolves and coyotes, for example, you could add the hierarchy for their genus: canis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9fc47",
   "metadata": {},
   "source": [
    "**4. Data Reduction:**\n",
    "\n",
    "The size of the dataset can be too large to be handled by data analysis and data mining algorithms.\n",
    "\n",
    "One possible solution is to obtain a reduced representation of the dataset that is much smaller in volume but produces the same quality of analytical results. For this, we use data reduction techniques.\n",
    "\n",
    "- **Data Cube Aggregation:** It is a way of data reduction, in which the gathered data is expressed in a summary form.\n",
    "\n",
    "\n",
    "- **Attribute Subset Selection:** The highly relevant attributes should be used, rest all can be discarded. It, essentially, combines tags or features.\n",
    "\n",
    "\n",
    "- **Numerosity Reduction:** The data can be represented as a model or equation like a regression model. This would save the burden of storing huge datasets instead of a model.\n",
    "\n",
    "\n",
    "- **Dimensionality Reduction:** This technique aims to reduce the number of redundant features we consider in machine learning algorithms. Dimensionality reduction can be done using techniques like Principal Component Analysis etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e396f1c",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd276a04",
   "metadata": {},
   "source": [
    "In this notebook we will try to apply steps of data preprocessing.\n",
    "\n",
    "The **dataset** that we will use contains 4 columns and it gives information about customers who bought or did not a related product:\n",
    "- **Country:** Country of the customer\n",
    "- **Age:** Age of the customer\n",
    "- **Salary:** Salary of the customer \n",
    "- **Purchased:** Information about if the customer buy the related product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f80b0",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08ef0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be958343",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c379a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a55be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01aa79f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beff24fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country    Age  Salary  Purchased\n",
       "0    False  False   False      False\n",
       "1    False  False   False      False\n",
       "2    False  False   False      False\n",
       "3    False  False   False      False\n",
       "4    False  False    True      False\n",
       "5    False  False   False      False\n",
       "6    False   True   False      False\n",
       "7    False  False   False      False\n",
       "8    False  False   False      False\n",
       "9    False  False   False      False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73534364",
   "metadata": {},
   "source": [
    "As seen above, we have two null values, we will handle them soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f9e6f",
   "metadata": {},
   "source": [
    "Now, we will extract dependent and independent variables. We have 3 independent variables that are **Country, Age** and **Salary**, and the dependent one is **Purchased** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3458e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daeaa3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97f5255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0486ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89b570",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e1356",
   "metadata": {},
   "source": [
    "We can handle missing data by two ways:\n",
    "- Ignore the tuples: when dataset is huge and multiple values are missing within a tuple.\n",
    "- Fill the missing values: fill the missing values manually, by attribute mean or the most probable value.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22e4f2",
   "metadata": {},
   "source": [
    "To handle missing values, we will use SimpleImputer function. It complements missing values with simple strategies. We will use fill them with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d701e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a027ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47492f88",
   "metadata": {},
   "source": [
    "The null values are filled with the mean of the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d30b4b",
   "metadata": {},
   "source": [
    "### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83eac2a",
   "metadata": {},
   "source": [
    "For encoding variables, we will use **One-hot encoding** which is the conversion of categorical information into a format that may be fed into machine learning algorithms to improve prediction accuracy. One-hot encoding is a common method for dealing with categorical data in machine learning. \n",
    "\n",
    "It is useful for data that has no relationship to each other and it represents categorical variables as binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac86395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "627f495e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ceade",
   "metadata": {},
   "source": [
    "For the **dependent variable**, we will use **label encoding**. Label Encoding is a popular encoding technique for handling categorical variables and it is useful **when there are only two possible values of a categorical features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7abfe581",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7aaaafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10e664",
   "metadata": {},
   "source": [
    "### Splitting The Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c364f",
   "metadata": {},
   "source": [
    "In data preprocessing, we divide our dataset into a training set and test set.\n",
    "\n",
    "The train_test_split function splits the data as 30% of the data will be test and the remaining values for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aabbaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46f23622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab5125b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35900deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f44e121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3793b",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c2e83",
   "metadata": {},
   "source": [
    "Feature scaling is a method used to normalize the range of independent variables or features of data. \n",
    "\n",
    "It we look at our dataset, we can see how values are far away from them in the Age and Salary column. With feature scaling, we will put our variables in the same range and in the same scale so that no any variable dominate the other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b89e59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fb7f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c2f823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecc06450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8660254 ,  1.58113883, -0.63245553, -0.03891021, -0.22960023],\n",
       "       [ 1.15470054, -0.63245553, -0.63245553,  0.50583275,  0.49120535],\n",
       "       [-0.8660254 , -0.63245553,  1.58113883, -0.31128169, -0.47311563],\n",
       "       [-0.8660254 , -0.63245553,  1.58113883, -1.80932482, -1.6127677 ],\n",
       "       [ 1.15470054, -0.63245553, -0.63245553,  1.0505757 ,  1.10486416],\n",
       "       [-0.8660254 ,  1.58113883, -0.63245553,  1.32294718,  1.45552633],\n",
       "       [ 1.15470054, -0.63245553, -0.63245553, -0.71983891, -0.73611226]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f794a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.17206578e-17,  1.00000000e+00, -3.17206578e-17,\n",
       "         3.00000000e+01,  5.40000000e+04],\n",
       "       [ 1.00000000e+00, -3.17206578e-17, -3.17206578e-17,\n",
       "         3.70000000e+01,  6.70000000e+04],\n",
       "       [-3.17206578e-17, -3.17206578e-17,  1.00000000e+00,\n",
       "         3.87777778e+01,  5.20000000e+04]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
